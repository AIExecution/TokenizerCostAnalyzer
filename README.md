# ğŸ” Tokenizer Cost Analyzer â€” Compare LLM Tokenization & â‚¹ Cost!

Ever wondered how much your prompt _really_ costs when sent to GPT-4, LLaMA, Claude, or Mistral?

Welcome to **Tokenizer Cost Analyzer** â€” a sleek Streamlit app that breaks down your prompt into tokens, compares how different models tokenize the same text, and shows you the estimated â‚¹ cost per model ğŸ’¸.

---

## âš™ï¸ What This App Does

- ğŸ§© **Tokenizes input text** using different model tokenizers (OpenAI GPT-4, LLaMA2, Mistral, Claude).
- ğŸ“Š **Estimates token count and cost** based on real-world pricing (â‚¹ per 1K tokens).
- ğŸ§  **Visualizes** which model is more efficient using token count and cost bar charts.
- ğŸ’¡ Helps you **optimize your prompts** by choosing models that tokenize more efficiently.

---

## ğŸ•¹ï¸ How to Use

1. **Enter your sentence** in the text box (e.g., _"I am becoming an AI thought leader."_).
2. Click **â€œAnalyze Tokenizationâ€**.
3. Instantly see:
   - Model-wise token breakdown ğŸ§©
   - Token IDs ğŸ”¢
   - Estimated cost in â‚¹ ğŸ’°
   - Clean side-by-side comparison table
   - Beautiful charts comparing token count & cost

---

## ğŸ“¸ Preview

| Model | Tokens              | Token IDs        | Token Count | â‚¹ Cost    |
| ----- | ------------------- | ---------------- | ----------- | --------- |
| GPT-4 | `['I', ' am', ...]` | `[40, 539, ...]` | `9`         | `â‚¹0.0054` |

![Sample UI](https://your-screenshot-url.com/sample.png) <!-- Replace with actual screenshot URL if available -->

---

## ğŸš€ Run It Locally

# Clone the repo

git clone https://github.com/your-username/tokenizer-cost-analyzer.git](https://github.com/AIExecution/TokenizerCostAnalyzer.git
cd tokenizer-cost-analyzer

# Install dependencies

pip install -r requirements.txt

# Add Hufgging Face token value

Make sure you agree to terms and conditions for below models in hugging face otherwise the token might not be useful.
https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1

Replace hf_your_actual_token_here with your actual token in .env file.

HF_TOKEN=hf_your_actual_token_here

# Run the app

streamlit run app.py

# If you want to check Tokeniser for specific model and get their computation details run

streamlit run tokenizer_decoder_app.py

## ğŸŒ Run It on Hugging Face Spaces (No Setup Needed)

Just click **â€œOpen in Spacesâ€** (if deployed), or **fork and deploy your own**:

---

## ğŸ§  Powered By

- ğŸ¤– [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- ğŸ§® [tiktoken (OpenAI)](https://github.com/openai/tiktoken)
- ğŸ¨ [matplotlib](https://matplotlib.org/)
- ğŸ“Š [plotly](https://plotly.com/python/)
- ğŸ§± [Streamlit](https://streamlit.io)

---

## ğŸ“¬ Contact & Credits

Built with â¤ï¸ by **Ashwin Shah** â€” feel free to fork, remix, or contribute!

---

## ğŸ“œ License

**MIT License** â€” free to use and adapt!
